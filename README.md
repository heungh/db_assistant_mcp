# DB Assistant MCP Server - í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ ê°€ì´ë“œ

**AI ê¸°ë°˜ AWS Aurora MySQL ì„±ëŠ¥ ë¶„ì„ ë° ìµœì í™” ìë™í™” ì‹œìŠ¤í…œ**

> Amazon Q CLIì™€ ìì—°ì–´ë¡œ ëŒ€í™”í•˜ë©° AWS RDS Aurora ë°ì´í„°ë² ì´ìŠ¤ë¥¼ AI ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ê³  ìµœì í™”í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ì†”ë£¨ì…˜

---

## ëª©ì°¨

- [ê°œìš”](#ê°œìš”)
- [ì•„í‚¤í…ì²˜](#ì•„í‚¤í…ì²˜)
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](#í”„ë¡œì íŠ¸-êµ¬ì¡°)
- [í•µì‹¬ ê¸°ëŠ¥](#í•µì‹¬-ê¸°ëŠ¥)
- [í™˜ê²½ ì„¤ì •](#í™˜ê²½-ì„¤ì •)
- [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
- [í•µì‹¬ ì†ŒìŠ¤ì½”ë“œ](#í•µì‹¬-ì†ŒìŠ¤ì½”ë“œ)
- [Lambda í•¨ìˆ˜ ëª©ë¡](#lambda-í•¨ìˆ˜-ëª©ë¡)

---

## ê°œìš”

**DB Assistant MCP Server**ëŠ” AWS Aurora MySQL ë°ì´í„°ë² ì´ìŠ¤ì˜ ì„±ëŠ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³ , AIë¥¼ í™œìš©í•˜ì—¬ ìµœì í™” ê¶Œì¥ì‚¬í•­ì„ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ì§€ëŠ¥í˜• ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ë„êµ¬ì…ë‹ˆë‹¤.

### í•µì‹¬ ê°€ì¹˜

- **AI ê¸°ë°˜ ë¶„ì„**: AWS Bedrock (Claude Sonnet 4, ë¦¬ì „: us-west-2)ì„ í™œìš©í•œ ì§€ëŠ¥í˜• ì„±ëŠ¥ ë¶„ì„
- **RAG ê¸°ë°˜ ê¶Œì¥ì‚¬í•­**: Bedrock Knowledge Base (ë¦¬ì „: us-east-1)ë¥¼ í†µí•œ Aurora MySQL ìµœì í™” ê°€ì´ë“œ ê²€ìƒ‰
- **í¬ê´„ì  ë¦¬í¬íŠ¸**: HTML í˜•ì‹ì˜ ì •êµí•œ ì„±ëŠ¥ ì§„ë‹¨ ë³´ê³ ì„œ ìë™ ìƒì„±
- **í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜**: Lambda + EC2 êµ¬ì¡°ë¡œ í™•ì¥ì„±ê³¼ ë³µì¡í•œ ë¶„ì„ì˜ ê· í˜• ë‹¬ì„±
- **ìì—°ì–´ ì¸í„°í˜ì´ìŠ¤**: Amazon Q CLIë¥¼ í†µí•œ ëŒ€í™”í˜• ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬
- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: CloudWatch ë©”íŠ¸ë¦­ ê¸°ë°˜ ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¶”ì 

### ì£¼ìš” ë¬¸ì œ í•´ê²°

- ë³µì¡í•œ RDS ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ì´í•´í•˜ê¸° ì‰¬ìš´ HTML ë¦¬í¬íŠ¸ë¡œ ë³€í™˜
- ëŠë¦° ì¿¼ë¦¬ ìë™ íƒì§€ ë° ìµœì í™” ê¶Œì¥ì‚¬í•­ ì œê³µ
- Aurora í´ëŸ¬ìŠ¤í„° ì „ì²´ì˜ ë¶€í•˜ ë¶„ì‚° ë° ë ˆí”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ëª¨ë‹ˆí„°ë§
- CPU, ë©”ëª¨ë¦¬, I/O, ì»¤ë„¥ì…˜ ë“± ë‹¤ì°¨ì› ì„±ëŠ¥ ë¶„ì„
- SQL ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë° ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„

---

## ì•„í‚¤í…ì²˜

### í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ (Lambda + EC2)

```mermaid
graph TB
    User[ğŸ‘¤ ì‚¬ìš©ì<br/>Amazon Q CLI] -->|ìì—°ì–´ ì§ˆì˜| Q[Amazon Q]
    Q -->|MCP Protocol| MCP[MCP Server<br/>db_assistant_mcp_server.py<br/>EC2 Instance]

    subgraph "EC2 - ë³µì¡í•œ ë¶„ì„ & AI"
        MCP -->|Lambda í˜¸ì¶œ| L1[Lambda: validate_schema]
        MCP -->|Lambda í˜¸ì¶œ| L2[Lambda: explain_query]
        MCP -->|Lambda í˜¸ì¶œ| L3[Lambda: get_rds_cluster_info]
        MCP -->|Lambda í˜¸ì¶œ| L4[Lambda: get_cloudwatch_metrics_raw]

        L1 -->|ìŠ¤í‚¤ë§ˆ ê²€ì¦ ê²°ê³¼| MCP
        L2 -->|EXPLAIN ë¶„ì„ ê²°ê³¼| MCP
        L3 -->|RDS ë©”íƒ€ë°ì´í„°| MCP
        L4 -->|936 ë°ì´í„° í¬ì¸íŠ¸| MCP

        MCP -->|ë°ì´í„° ë¶„ì„| Analysis[ë°ì´í„° ë¶„ì„ ì—”ì§„<br/>Pandas, Numpy]
        Analysis -->|CSV ìƒì„±| CSV[(CSV Files)]
        Analysis -->|ìƒê´€ê´€ê³„| Corr[ìƒê´€ê´€ê³„ ë¶„ì„]
        Analysis -->|ì´ìƒì¹˜| Outlier[ì´ìƒ ì§•í›„ íƒì§€]

        MCP -->|RAG ê²€ìƒ‰| KB[Bedrock Knowledge Base<br/>Aurora MySQL ìµœì í™” ê°€ì´ë“œ]
        KB -->|ìµœì í™” ë¬¸ì„œ| MCP

        MCP -->|AI ë¶„ì„ ìš”ì²­| Claude[Claude Sonnet 4<br/>Bedrock Runtime]
        Claude -->|ë§ì¶¤í˜• ê¶Œì¥ì‚¬í•­| MCP

        MCP -->|HTML ìƒì„±| HTML[HTML Report Generator<br/>modules/report_generator.py]
        HTML -->|ë¦¬í¬íŠ¸| Output[(Output Files<br/>HTML/CSV/SQL)]
    end

    subgraph "AWS Services"
        L1 & L2 -->|DB ì—°ê²°| RDS[(AWS RDS<br/>Aurora MySQL)]
        L3 -->|DescribeDBClusters| RDS
        L4 -->|GetMetricStatistics| CW[CloudWatch<br/>Metrics & Logs]
        Output -->|Upload| S3[S3 Bucket<br/>db-assistant-reports]
    end

    S3 -->|Presigned URL<br/>7ì¼ ìœ íš¨| User

    style MCP fill:#667eea,color:#fff
    style Analysis fill:#27ae60,color:#fff
    style Claude fill:#e74c3c,color:#fff
    style HTML fill:#3498db,color:#fff
    style L1 fill:#f39c12,color:#fff
    style L2 fill:#f39c12,color:#fff
```

### ë°ì´í„° íë¦„

1. **ì‚¬ìš©ì ìš”ì²­** â†’ Amazon Q CLIì—ì„œ ìì—°ì–´ë¡œ ì„±ëŠ¥ ë¶„ì„ ë˜ëŠ” SQL ê²€ì¦ ìš”ì²­
2. **MCP ì„œë²„ ì‹¤í–‰** â†’ db_assistant_mcp_server.pyê°€ ìš”ì²­ì„ ì²˜ë¦¬
3. **Lambda í˜¸ì¶œ** â†’ ìŠ¤í‚¤ë§ˆ ê²€ì¦, EXPLAIN ë¶„ì„, RDS ì •ë³´, CloudWatch ë©”íŠ¸ë¦­ ìˆ˜ì§‘
4. **ë¡œì»¬ ë¶„ì„** â†’ EC2ì—ì„œ Pandasë¥¼ ì‚¬ìš©í•œ ìƒê´€ê´€ê³„ ë¶„ì„, ì´ìƒ ì§•í›„ íƒì§€
5. **AI ë¶„ì„** â†’ Bedrock Knowledge Base RAG ê²€ìƒ‰ + Claude Sonnet 4 ê¶Œì¥ì‚¬í•­ ìƒì„±
6. **ë¦¬í¬íŠ¸ ìƒì„±** â†’ HTML + CSV + SQL íŒŒì¼ ìƒì„±
7. **S3 ì—…ë¡œë“œ** â†’ ë¦¬í¬íŠ¸ íŒŒì¼ì„ S3ì— ì—…ë¡œë“œ, presigned URL ìƒì„± (7ì¼ ìœ íš¨)

### ì•„í‚¤í…ì²˜ ì¥ì 

| íŠ¹ì§• | Lambda Only | **í•˜ì´ë¸Œë¦¬ë“œ (í˜„ì¬)** | EC2 Only |
|------|-------------|---------------------|----------|
| í™•ì¥ì„± | âœ… ë†’ìŒ | âœ… ë†’ìŒ | âš ï¸ ì œí•œì  |
| ë³µì¡í•œ ë¶„ì„ | âŒ ì œí•œì  (ë©”ëª¨ë¦¬/ì‹œê°„) | âœ… ê°€ëŠ¥ | âœ… ê°€ëŠ¥ |
| ë¹„ìš© íš¨ìœ¨ | âœ… ë†’ìŒ | âœ… ì¤‘ê°„ | âš ï¸ ë‚®ìŒ |
| Pandas/AI í†µí•© | âŒ ì–´ë ¤ì›€ | âœ… ì‰¬ì›€ | âœ… ì‰¬ì›€ |
| DB ì—°ê²° ê´€ë¦¬ | âš ï¸ Lambdaì—ì„œ ì§ì ‘ | âœ… Lambdaë¡œ ì˜¤í”„ë¡œë“œ | âš ï¸ EC2ì—ì„œ ì§ì ‘ |

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
db-assistant/
â”œâ”€â”€ README.md                           # ì´ íŒŒì¼
â”œâ”€â”€ requirements.txt                    # Python ì˜ì¡´ì„±
â”‚
â”œâ”€â”€ db_assistant_mcp_server.py          # ğŸ¯ MCP ë©”ì¸ ì„œë²„ (500KB, 10000+ lines)
â”‚
â”œâ”€â”€ lambda-functions/                   # Lambda í•¨ìˆ˜ë“¤ (ì‹¤ì œ ì‚¬ìš©: 12ê°œ)
â”‚   â”‚
â”‚   â”œâ”€â”€ validate_schema/                # â­ DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦
â”‚   â”‚   â””â”€â”€ handler.py
â”‚   â”œâ”€â”€ explain_query/                  # â­ ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„ (EXPLAIN)
â”‚   â”‚   â””â”€â”€ handler.py
â”‚   â”œâ”€â”€ get_rds_cluster_info/           # â­ RDS í´ëŸ¬ìŠ¤í„° ì •ë³´ ìˆ˜ì§‘
â”‚   â”‚   â””â”€â”€ handler.py
â”‚   â”œâ”€â”€ get_cloudwatch_metrics_raw/     # â­ CloudWatch ë©”íŠ¸ë¦­ ìˆ˜ì§‘
â”‚   â”‚   â””â”€â”€ handler.py
â”‚   â”‚
â”‚   â”œâ”€â”€ collect_cpu_intensive_queries/  # CPU ì§‘ì•½ ì¿¼ë¦¬ ìˆ˜ì§‘
â”‚   â”‚   â””â”€â”€ handler.py
â”‚   â”œâ”€â”€ collect_temp_space_intensive_queries/  # ì„ì‹œ ê³µê°„ ì§‘ì•½ ì¿¼ë¦¬ ìˆ˜ì§‘
â”‚   â”‚   â””â”€â”€ handler.py
â”‚   â”œâ”€â”€ collect_memory_intensive_queries/  # ë©”ëª¨ë¦¬ ì§‘ì•½ ì¿¼ë¦¬ ìˆ˜ì§‘
â”‚   â”‚   â””â”€â”€ handler.py
â”‚   â”œâ”€â”€ collect_slow_queries_cloudwatch/  # CloudWatch Slow Query ìˆ˜ì§‘
â”‚   â”‚   â””â”€â”€ handler.py
â”‚   â”œâ”€â”€ collect_cluster_metrics/        # í´ëŸ¬ìŠ¤í„° ë©”íŠ¸ë¦­ ìˆ˜ì§‘
â”‚   â”‚   â””â”€â”€ handler.py
â”‚   â”œâ”€â”€ collect_cluster_events/         # í´ëŸ¬ìŠ¤í„° ì´ë²¤íŠ¸ ìˆ˜ì§‘
â”‚   â”‚   â””â”€â”€ handler.py
â”‚   â”‚
â”‚   â”œâ”€â”€ get_secret/                     # Secret ì¡°íšŒ
â”‚   â”‚   â””â”€â”€ handler.py
â”‚   â””â”€â”€ list_secrets/                   # Secret ëª©ë¡
â”‚       â””â”€â”€ handler.py
â”‚
â”œâ”€â”€ utils/                              # ìœ í‹¸ë¦¬í‹° (4ê°œ, ì‹¤ì œ ì‚¬ìš©)
â”‚   â”œâ”€â”€ constants.py                    # ìƒìˆ˜ ì •ì˜ (OUTPUT_DIR, DEFAULT_REGION ë“±)
â”‚   â”œâ”€â”€ formatters.py                   # í¬ë§·í„° (bytes, number, percentage ë“±)
â”‚   â”œâ”€â”€ logging_utils.py                # ë¡œê¹… ìœ í‹¸ë¦¬í‹°
â”‚   â””â”€â”€ parsers.py                      # íŒŒì„œ (í…Œì´ë¸”ëª…, SQL íƒ€ì… ë“±)
â”‚
â”œâ”€â”€ output/                             # HTML ë¦¬í¬íŠ¸ ì¶œë ¥
â”‚   â”œâ”€â”€ comprehensive_performance_report_*.html
â”‚   â”œâ”€â”€ cluster_performance_report_*.html
â”‚   â””â”€â”€ validation_report_*.html
â”‚
â”œâ”€â”€ data/                               # CSV ë°ì´í„° íŒŒì¼
â”‚   â””â”€â”€ database_metrics_*.csv
â”‚
â”œâ”€â”€ sql/                                # SQL ì¿¼ë¦¬ íŒŒì¼
â”‚   â”œâ”€â”€ cpu_intensive_queries_*.sql
â”‚   â””â”€â”€ temp_space_intensive_queries_*.sql
â”‚
â””â”€â”€ logs/                               # ë¡œê·¸ íŒŒì¼
    â””â”€â”€ mcp_server_*.log
```

---

## í•µì‹¬ ê¸°ëŠ¥

### 1. SQL ìŠ¤í‚¤ë§ˆ ê²€ì¦ (`validate_schema_lambda`)

**ëª©ì **: SQL DDL êµ¬ë¬¸ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•˜ì—¬ ì‹¤í–‰ ì „ ì˜¤ë¥˜ë¥¼ ë°©ì§€

**ì£¼ìš” ê¸°ëŠ¥**:
- CREATE TABLE, ALTER TABLE, DROP TABLE, CREATE INDEX ê²€ì¦
- í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
- ì™¸ë˜ í‚¤ ì°¸ì¡° í…Œì´ë¸” ê²€ì¦
- IF NOT EXISTS / IF EXISTS êµ¬ë¬¸ ë¶„ì„
- MIXED_DDL ì§€ì› (ì—¬ëŸ¬ DDL íƒ€ì… í˜¼í•©)
- í•œê¸€ ì£¼ì„ ì•ˆì „ ì²˜ë¦¬

**Lambda í•¨ìˆ˜**: `validate_schema` (db-assistant-validate-schema-dev)

**ì‹¤í–‰ ì˜ˆì‹œ**:
```python
# MCP ì„œë²„ì—ì„œ Lambda í˜¸ì¶œ
result = await self.validate_schema_lambda(
    database_secret="gamedb1-cluster",
    database="gamedb",
    ddl_content="CREATE TABLE IF NOT EXISTS users (...)"
)

# ê²°ê³¼
{
    'success': True,
    'valid': True,
    'ddl_type': 'CREATE_TABLE',
    'table_name': 'users',
    'issues': [],
    'warnings': ['í…Œì´ë¸” usersì´ ì´ë¯¸ ì¡´ì¬í•¨ (IF NOT EXISTS ì‚¬ìš©ìœ¼ë¡œ ë¬¸ì œì—†ìŒ)'],
    's3_location': 's3://db-assistant-query-results-dev/schema-validation/...'
}
```

---

### 2. ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„ (`explain_query_lambda`)

**ëª©ì **: SELECT/UPDATE/DELETE/INSERT/REPLACE ì¿¼ë¦¬ì˜ ì‹¤í–‰ ê³„íšì„ ë¶„ì„í•˜ì—¬ ì„±ëŠ¥ ì´ìŠˆë¥¼ ì‚¬ì „ì— ë°œê²¬

**ì£¼ìš” ê¸°ëŠ¥**:
- EXPLAIN ì‹¤í–‰ ë° ê²°ê³¼ íŒŒì‹±
- Full Table Scan ê°ì§€
- ì¸ë±ìŠ¤ ë¯¸ì‚¬ìš© ê°ì§€
- Using filesort / Using temporary ê°ì§€
- ë§ì€ í–‰ ìŠ¤ìº” ê²½ê³  (100,000ê°œ ì´ìƒ)
- ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­ ìë™ ìƒì„±

**Lambda í•¨ìˆ˜**: `explain_query` (db-assistant-explain-query-dev)

**ì‹¤í–‰ ì˜ˆì‹œ**:
```python
# MCP ì„œë²„ì—ì„œ Lambda í˜¸ì¶œ
result = await self.explain_query_lambda(
    database_secret="gamedb1-cluster",
    database="gamedb",
    query="SELECT * FROM users WHERE email = 'test@example.com'"
)

# ê²°ê³¼
{
    'success': True,
    'query': "SELECT * FROM users WHERE email = 'test@example.com'",
    'explain_data': [
        {
            'id': 1,
            'select_type': 'SIMPLE',
            'table': 'users',
            'type': 'ALL',  # Full Table Scan!
            'possible_keys': None,
            'key': None,
            'rows': 10000,
            'Extra': 'Using where'
        }
    ],
    'performance_issues': [
        {
            'severity': 'HIGH',
            'issue': 'Full Table Scan',
            'table': 'users',
            'rows': 10000,
            'description': "í…Œì´ë¸” 'users'ì—ì„œ ì „ì²´ í…Œì´ë¸” ìŠ¤ìº” ë°œìƒ"
        }
    ],
    'recommendations': ["í…Œì´ë¸” 'users'ì— email ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì¶”ê°€ ê¶Œì¥"],
    's3_location': 's3://db-assistant-query-results-dev/explain-results/...'
}
```

---

### 3. ì¢…í•© ì„±ëŠ¥ ì§„ë‹¨ ë³´ê³ ì„œ (`generate_comprehensive_performance_report`)

**ëª©ì **: Aurora MySQL ì¸ìŠ¤í„´ìŠ¤ì˜ ì „ì²´ ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ HTML ë¦¬í¬íŠ¸ ìƒì„±

**ì£¼ìš” ê¸°ëŠ¥**:
- CloudWatch ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (936ê°œ ë°ì´í„° í¬ì¸íŠ¸)
  - CPU ì‚¬ìš©ë¥ , ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìˆ˜, ì—¬ìœ  ë©”ëª¨ë¦¬
  - Read/Write IOPS, Latency, Throughput
  - ë„¤íŠ¸ì›Œí¬ ì†¡ìˆ˜ì‹  ì²˜ë¦¬ëŸ‰
  - Buffer Cache Hit Ratio
- Pandas ê¸°ë°˜ ë°ì´í„° ë¶„ì„
  - CSV íŒŒì¼ë¡œ ì›ë³¸ ë°ì´í„° ì €ì¥
  - ì‹œê³„ì—´ ë°ì´í„° ìƒê´€ê´€ê³„ ë¶„ì„
  - ì´ìƒ ì§•í›„ íƒì§€ (Outlier Detection)
- ëŠë¦° ì¿¼ë¦¬ ë¶„ì„ (CloudWatch Logs)
- AI ê¸°ë°˜ ìµœì í™” ê¶Œì¥ì‚¬í•­ (Bedrock RAG + Claude Sonnet 4)
- HTML ë¦¬í¬íŠ¸ ìƒì„± (ë°˜ì‘í˜• ë””ìì¸, ê·¸ë¼ë°ì´ì…˜)

**Lambda í•¨ìˆ˜ ì‚¬ìš©**:
- `get_rds_cluster_info` - RDS ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
- `get_cloudwatch_metrics_raw` - CloudWatch ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (936ê°œ í¬ì¸íŠ¸)

**ì‹¤í–‰ ì˜ˆì‹œ**:
```python
# MCP ì„œë²„ í˜¸ì¶œ
result = await server.generate_comprehensive_performance_report(
    database_secret="gamedb1-cluster",
    db_instance_identifier="gamedb1-1",
    region="ap-northeast-2",
    hours=6
)
```

**ìƒì„± íŒŒì¼**:
- `comprehensive_performance_report_gamedb1-1_20251023_102840.html` (34KB)
- `database_metrics_gamedb1-1_20251023_102841.csv` (12KB)
- `cpu_intensive_queries_gamedb1-1_20251023.sql` (2KB)
- `temp_space_intensive_queries_gamedb1-1_20251023.sql` (2KB)

---

### 4. SQL íŒŒì¼ ê²€ì¦ ë° í†µí•© ë³´ê³ ì„œ (`validate_sql_files`)

**ëª©ì **: ì—¬ëŸ¬ SQL íŒŒì¼ì„ ì¼ê´„ ê²€ì¦í•˜ê³  í†µí•© HTML ë³´ê³ ì„œ ìƒì„±

**ì£¼ìš” ê¸°ëŠ¥**:
- ë³µìˆ˜ SQL íŒŒì¼ ê²€ì¦
- DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦ (Lambda: validate_schema)
- DML ì¿¼ë¦¬ EXPLAIN ë¶„ì„ (Lambda: explain_query)
- ê°œë³„ HTML ë³´ê³ ì„œ ìƒì„±
- í†µí•© HTML ë³´ê³ ì„œ ìë™ ìƒì„± (2ê°œ ì´ìƒ íŒŒì¼)
  - ì´ íŒŒì¼ ìˆ˜, í†µê³¼/ì‹¤íŒ¨ ê±´ìˆ˜, í†µê³¼ìœ¨
  - ê°œë³„ ë³´ê³ ì„œ ë§í¬

**ì‹¤í–‰ ì˜ˆì‹œ**:
```python
# MCP ì„œë²„ í˜¸ì¶œ
result = await server.validate_sql_files(
    filenames=[
        '/path/to/comprehensive_dml_test.sql',
        '/path/to/advanced_complex_queries_test.sql',
        '/path/to/slow_example.sql'
    ],
    database_secret='gamedb1-cluster'
)
```

**ì¶œë ¥**:
```
âœ… comprehensive_dml_test.sql: âŒ ë°œê²¬ëœ ë¬¸ì œ: AI ë¶„ì„ ë¬¸ì œ, ê¸°íƒ€ ë¬¸ì œ 2ê±´
âœ… advanced_complex_queries_test.sql: âŒ ë°œê²¬ëœ ë¬¸ì œ: AI ë¶„ì„ ë¬¸ì œ, ê¸°íƒ€ ë¬¸ì œ 9ê±´
âœ… slow_example.sql: âœ… ëª¨ë“  ê²€ì¦ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤.

ğŸ“Š í†µí•© ê²€ì¦ ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: /path/to/consolidated_validation_report_20251023_161045.html
   ì´ 3ê°œ íŒŒì¼, í†µê³¼: 1, ì‹¤íŒ¨: 2, í†µê³¼ìœ¨: 33.3%
```

---

## í™˜ê²½ ì„¤ì •

### 1. EC2 ì¸ìŠ¤í„´ìŠ¤ ì„¤ì •

```bash
# SSH ì ‘ì†
ssh -i your-key.pem ec2-user@your-ec2-ip

# Python 3.11 ë° í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜
sudo yum update -y
sudo yum install -y python3.11 python3.11-pip git

# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p ~/db-assistant
cd ~/db-assistant

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python3.11 -m venv venv
source venv/bin/activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install --upgrade pip
pip install boto3 pandas numpy pymysql mcp sqlparse scikit-learn matplotlib
```

### 2. Lambda í•¨ìˆ˜ ë°°í¬

**í•µì‹¬ Lambda í•¨ìˆ˜** (ìˆ˜ë™ ë°°í¬ í•„ìš”):
1. `validate_schema` - DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦
2. `explain_query` - ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„
3. `get_rds_cluster_info` - RDS ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
4. `get_cloudwatch_metrics_raw` - CloudWatch ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```bash
# Lambda í•¨ìˆ˜ ë°°í¬ ì˜ˆì‹œ (validate_schema)
cd lambda-functions/validate_schema
zip -r validate_schema.zip handler.py pymysql/

aws lambda update-function-code \
  --function-name db-assistant-validate-schema-dev \
  --zip-file fileb://validate_schema.zip \
  --region ap-northeast-2
```

### 3. AWS Credentials ì„¤ì •

```bash
# AWS credentials êµ¬ì„±
aws configure

# Secrets Managerì— ë°ì´í„°ë² ì´ìŠ¤ ì ‘ì† ì •ë³´ ì €ì¥
aws secretsmanager create-secret \
  --name gamedb1-cluster \
  --description "RDS Aurora MySQL credentials" \
  --secret-string '{
    "username": "admin",
    "password": "your-password",
    "host": "your-cluster.cluster-xxx.ap-northeast-2.rds.amazonaws.com",
    "port": "3306",
    "dbClusterIdentifier": "gamedb1-cluster",
    "dbname": "gamedb"
  }' \
  --region ap-northeast-2
```

### 4. Amazon Q CLI ì„¤ì •

```bash
# MCP ì„¤ì • íŒŒì¼ ìƒì„±
mkdir -p ~/.aws/amazonq
cat > ~/.aws/amazonq/mcp.json << 'EOF'
{
  "mcpServers": {
    "db-assistant": {
      "command": "/home/ec2-user/db-assistant/venv/bin/python3",
      "args": ["/home/ec2-user/db-assistant/db_assistant_mcp_server.py"],
      "env": {
        "AWS_DEFAULT_REGION": "ap-northeast-2",
        "PYTHONPATH": "/home/ec2-user/db-assistant",
        "PATH": "/home/ec2-user/db-assistant/venv/bin:/usr/local/bin:/usr/bin:/bin"
      },
      "disabled": false,
      "timeout": 300000,
      "autoApprove": [
        "validate_sql_files",
        "generate_comprehensive_performance_report"
      ]
    }
  }
}
EOF
```

### 5. S3 ë²„í‚· ìƒì„±

```bash
# ë¦¬í¬íŠ¸ ì €ì¥ìš© S3 ë²„í‚· ìƒì„±
aws s3 mb s3://db-assistant-reports --region ap-northeast-2

# Lambda ê²°ê³¼ ì €ì¥ìš© S3 ë²„í‚· ìƒì„±
aws s3 mb s3://db-assistant-query-results-dev --region ap-northeast-2
```

### 6. Bedrock ë° Knowledge Base ì„¤ì •

```bash
# Bedrock ë¦¬ì „: us-west-2 (Claude Sonnet 4 ì‚¬ìš©)
# Knowledge Base ë¦¬ì „: us-east-1 (Aurora MySQL ìµœì í™” ê°€ì´ë“œ)

# IAM ê¶Œí•œ í™•ì¸ (EC2 ì¸ìŠ¤í„´ìŠ¤ ë¡¤ ë˜ëŠ” ì‚¬ìš©ì ê¶Œí•œ)
# - bedrock:InvokeModel (us-west-2)
# - bedrock-agent:Retrieve (us-east-1)

# í•„ìš”í•œ IAM ì •ì±… ì˜ˆì‹œ
cat > bedrock-policy.json << 'EOF'
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "bedrock:InvokeModel"
      ],
      "Resource": "arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-sonnet-4*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "bedrock-agent:Retrieve"
      ],
      "Resource": "arn:aws:bedrock:us-east-1:*:knowledge-base/*"
    }
  ]
}
EOF

# IAM ì •ì±… ìƒì„± ë° ì—°ê²° (ì„ íƒì‚¬í•­)
aws iam create-policy \
  --policy-name db-assistant-bedrock-policy \
  --policy-document file://bedrock-policy.json

# EC2 ì¸ìŠ¤í„´ìŠ¤ ë¡¤ì— ì •ì±… ì—°ê²° (EC2 ì‚¬ìš© ì‹œ)
# aws iam attach-role-policy \
#   --role-name your-ec2-role-name \
#   --policy-arn arn:aws:iam::YOUR-ACCOUNT-ID:policy/db-assistant-bedrock-policy
```

**Knowledge Base ID ì„¤ì •**:
- Knowledge Base IDëŠ” `utils/constants.py`ì—ì„œ `KNOWLEDGE_BASE_ID` ë³€ìˆ˜ë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤
- ì‹¤ì œ Knowledge Baseë¥¼ ìƒì„±í•œ í›„ IDë¥¼ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤

---

## ì‚¬ìš© ë°©ë²•

### 1. SQL íŒŒì¼ ê²€ì¦

```bash
# Amazon Q CLI ì‹¤í–‰
q

# ìì—°ì–´ë¡œ ìš”ì²­
"comprehensive_dml_test.sql íŒŒì¼ì„ ê²€ì¦í•´ì¤˜"
```

**ë‚´ë¶€ ë™ì‘**:
1. MCP ì„œë²„ê°€ SQL íŒŒì¼ ì½ê¸°
2. SQL íƒ€ì… ê°ì§€ (DDL / DML / MIXED)
3. DDLì¸ ê²½ìš°: `validate_schema_lambda` í˜¸ì¶œ
4. DMLì¸ ê²½ìš°: `explain_query_lambda` í˜¸ì¶œ (ê° SELECT/UPDATE/DELETEë§ˆë‹¤)
5. HTML ë³´ê³ ì„œ ìƒì„± (`output/validation_report_*.html`)

### 2. ì„±ëŠ¥ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±

```bash
# Amazon Q CLIì—ì„œ
"gamedb1-1 ì¸ìŠ¤í„´ìŠ¤ì˜ ìµœê·¼ 6ì‹œê°„ ì„±ëŠ¥ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•´ì¤˜"
```

**ë‚´ë¶€ ë™ì‘**:
1. `get_rds_cluster_info` Lambda í˜¸ì¶œ â†’ RDS ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
2. `get_cloudwatch_metrics_raw` Lambda í˜¸ì¶œ â†’ 936ê°œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
3. Pandas ë°ì´í„° ë¶„ì„ (EC2) â†’ CSV ìƒì„±, ìƒê´€ê´€ê³„ ë¶„ì„
4. Bedrock Knowledge Base RAG ê²€ìƒ‰ â†’ Aurora ìµœì í™” ë¬¸ì„œ
5. Claude Sonnet 4 AI ë¶„ì„ â†’ ë§ì¶¤í˜• ê¶Œì¥ì‚¬í•­
6. HTML ë¦¬í¬íŠ¸ ìƒì„± â†’ S3 ì—…ë¡œë“œ â†’ presigned URL ë°˜í™˜

### 3. ì—¬ëŸ¬ SQL íŒŒì¼ ì¼ê´„ ê²€ì¦

```bash
# Amazon Q CLIì—ì„œ
"sql ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  SQL íŒŒì¼ì„ ê²€ì¦í•˜ê³  í†µí•© ë³´ê³ ì„œë¥¼ ë§Œë“¤ì–´ì¤˜"
```

**ë‚´ë¶€ ë™ì‘**:
1. ê° SQL íŒŒì¼ ê°œë³„ ê²€ì¦
2. ê°œë³„ HTML ë³´ê³ ì„œ ìƒì„±
3. í†µí•© HTML ë³´ê³ ì„œ ìë™ ìƒì„± (2ê°œ ì´ìƒ)
   - í†µê³¼ìœ¨, í†µê³¼/ì‹¤íŒ¨ ê±´ìˆ˜
   - ê°œë³„ ë³´ê³ ì„œ ë§í¬

---

## í•µì‹¬ ì†ŒìŠ¤ì½”ë“œ

### 1. Lambda í˜¸ì¶œ í—¬í¼ (`_call_lambda`)

**ìœ„ì¹˜**: `db_assistant_mcp_server.py:164-196`

```python
async def _call_lambda(self, function_name: str, payload: dict) -> dict:
    """
    Lambda í•¨ìˆ˜ í˜¸ì¶œ í—¬í¼ (í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ìš©)

    RDS/CloudWatch API í˜¸ì¶œì„ Lambdaë¡œ ì˜¤í”„ë¡œë“œí•˜ì—¬
    ì›ë³¸ ì„œë²„ëŠ” ë³µì¡í•œ ë¶„ì„ ë¡œì§ì—ë§Œ ì§‘ì¤‘
    """
    try:
        full_name = f"db-assistant-{function_name}-dev"
        logger.info(f"Lambda í˜¸ì¶œ: {full_name}")

        response = self.lambda_client.invoke(
            FunctionName=full_name,
            InvocationType='RequestResponse',
            Payload=json.dumps(payload)
        )

        result = json.loads(response['Payload'].read())

        if response['StatusCode'] == 200 and result.get('statusCode') == 200:
            body = result.get('body', '{}')
            if isinstance(body, str):
                body = json.loads(body)
            logger.info(f"Lambda í˜¸ì¶œ ì„±ê³µ: {full_name}")
            return body
        else:
            error_msg = result.get('body', {}).get('error', 'Unknown error')
            logger.error(f"Lambda ì˜¤ë¥˜: {error_msg}")
            raise Exception(f"Lambda ì˜¤ë¥˜: {error_msg}")

    except Exception as e:
        logger.error(f"Lambda í˜¸ì¶œ ì‹¤íŒ¨ ({function_name}): {str(e)}")
        raise
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- ëª¨ë“  Lambda í˜¸ì¶œì˜ ì¤‘ì•™ ê´€ë¦¬
- ì—ëŸ¬ ì²˜ë¦¬ í†µí•©
- ë¡œê¹… í†µí•©
- `RequestResponse` ë™ê¸° í˜¸ì¶œ (ê²°ê³¼ ì¦‰ì‹œ ë°˜í™˜)

---

### 2. ìŠ¤í‚¤ë§ˆ ê²€ì¦ Lambda í†µí•© (`validate_schema_lambda`)

**ìœ„ì¹˜**: `db_assistant_mcp_server.py:9052-9112`

```python
async def validate_schema_lambda(
    self,
    database_secret: str,
    database: str,
    ddl_content: str,
    region: str = "ap-northeast-2"
) -> dict:
    """DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦ (Lambda ì‚¬ìš©)

    Args:
        database_secret: Secrets Manager secret name
        database: ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
        ddl_content: DDL êµ¬ë¬¸
        region: AWS ë¦¬ì „

    Returns:
        dict: {
            'success': bool,
            'valid': bool,
            'ddl_type': str,
            'table_name': str,
            'issues': list,
            'warnings': list,
            's3_location': str
        }
    """
    try:
        # Lambdaê°€ database=None ì²˜ë¦¬ë¥¼ ë‹´ë‹¹
        logger.info(f"Lambdaë¡œ DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦: {database_secret}/{database}")

        # Lambda í˜¸ì¶œ
        lambda_result = await self._call_lambda('validate-schema', {
            'database_secret': database_secret,
            'database': database,
            'ddl_content': ddl_content,
            'region': region
        })

        if not lambda_result.get('success'):
            error_msg = lambda_result.get('error', 'Lambda í˜¸ì¶œ ì‹¤íŒ¨')
            logger.error(f"DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨ (Lambda): {error_msg}")
            return {
                'success': False,
                'valid': False,
                'error': error_msg
            }

        # Lambda ê²°ê³¼ ë°˜í™˜
        logger.info(f"DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì™„ë£Œ - Valid: {lambda_result.get('valid')}, "
                   f"Issues: {len(lambda_result.get('issues', []))}, "
                   f"Warnings: {len(lambda_result.get('warnings', []))}")

        return lambda_result

    except Exception as e:
        logger.error(f"DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
        return {
            'success': False,
            'valid': False,
            'error': str(e)
        }
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- Lambdaë¡œ DB ì—°ê²° ì˜¤í”„ë¡œë“œ
- EC2ëŠ” ê²°ê³¼ë§Œ ë°›ì•„ì„œ ì²˜ë¦¬
- ì—ëŸ¬ ë°œìƒ ì‹œ graceful ì²˜ë¦¬

---

### 3. EXPLAIN ë¶„ì„ Lambda í†µí•© (`explain_query_lambda`)

**ìœ„ì¹˜**: `db_assistant_mcp_server.py:9114-9172`

```python
async def explain_query_lambda(
    self,
    database_secret: str,
    database: str,
    query: str,
    region: str = "ap-northeast-2"
) -> dict:
    """ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„ (Lambda ì‚¬ìš©)

    Args:
        database_secret: Secrets Manager secret name
        database: ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
        query: ë¶„ì„í•  ì¿¼ë¦¬
        region: AWS ë¦¬ì „

    Returns:
        dict: {
            'success': bool,
            'query': str,
            'explain_data': list,
            'performance_issues': list,
            'performance_issue_count': int,
            'recommendations': list,
            's3_location': str
        }
    """
    try:
        # Lambdaê°€ database=None ì²˜ë¦¬ë¥¼ ë‹´ë‹¹
        logger.info(f"Lambdaë¡œ EXPLAIN ë¶„ì„: {database_secret}/{database}")

        # Lambda í˜¸ì¶œ
        lambda_result = await self._call_lambda('explain-query', {
            'database_secret': database_secret,
            'database': database,
            'query': query,
            'region': region
        })

        if not lambda_result.get('success'):
            error_msg = lambda_result.get('error', 'Lambda í˜¸ì¶œ ì‹¤íŒ¨')
            logger.error(f"EXPLAIN ë¶„ì„ ì‹¤íŒ¨ (Lambda): {error_msg}")
            return {
                'success': False,
                'error': error_msg
            }

        # Lambda ê²°ê³¼ ë°˜í™˜
        logger.info(f"EXPLAIN ë¶„ì„ ì™„ë£Œ - "
                   f"ì„±ëŠ¥ ì´ìŠˆ: {lambda_result.get('performance_issue_count', 0)}ê°œ, "
                   f"ê¶Œì¥ì‚¬í•­: {len(lambda_result.get('recommendations', []))}ê°œ")

        return lambda_result

    except Exception as e:
        logger.error(f"EXPLAIN ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- SELECT, UPDATE, DELETE, INSERT, REPLACE ëª¨ë‘ ì§€ì›
- Lambdaê°€ EXPLAIN ì‹¤í–‰
- ì„±ëŠ¥ ì´ìŠˆ ìë™ íƒì§€ (Full Table Scan, filesort, temporary ë“±)
- S3 ì €ì¥ ë° ë¡œê¹…

---

### 4. Lambda validate_schema í•¸ë“¤ëŸ¬

**ìœ„ì¹˜**: `lambda-functions/validate_schema/handler.py:20-151`

```python
def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦

    Parameters:
    - event: {
        "database_secret": "gamedb1-cluster",
        "database": "gamedb",
        "ddl_content": "CREATE TABLE users (...)",
        "region": "ap-northeast-2"
      }

    Returns:
    - statusCode: 200 (ì„±ê³µ) / 400 (ì…ë ¥ ì˜¤ë¥˜) / 500 (ì‹¤íŒ¨)
    - body: {
        "success": true/false,
        "valid": true/false,
        "ddl_type": "CREATE_TABLE",
        "issues": [...],
        "warnings": [...],
        "s3_location": "s3://..."
      }
    """
    connection = None

    try:
        database_secret = event.get('database_secret')
        database = event.get('database')
        ddl_content = event.get('ddl_content')
        region = event.get('region', 'ap-northeast-2')

        # ì…ë ¥ ê²€ì¦
        if not all([database_secret, database, ddl_content]):
            return {
                'statusCode': 400,
                'body': {
                    'success': False,
                    'error': 'database_secret, database, ddl_content í•„ìˆ˜'
                }
            }

        logger.info(f"DDL ê²€ì¦ ì‹œì‘: {database_secret}/{database}")

        # DDL íƒ€ì… ë¶„ì„
        ddl_type = detect_ddl_type(ddl_content)
        logger.info(f"DDL íƒ€ì…: {ddl_type}")

        # Secrets Managerì—ì„œ DB ì ‘ì† ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        secrets_client = boto3.client('secretsmanager', region_name=region)
        secret_response = secrets_client.get_secret_value(SecretId=database_secret)
        secret = json.loads(secret_response['SecretString'])

        # DB ì—°ê²°
        connection = pymysql.connect(
            host=secret.get('host'),
            port=int(secret.get('port', 3306)),
            user=secret.get('username'),
            password=secret.get('password'),
            database=database,
            connect_timeout=10
        )

        cursor = connection.cursor()
        logger.info("DB ì—°ê²° ì„±ê³µ")

        # ê²€ì¦ ìˆ˜í–‰
        result = {
            'success': True,
            'valid': True,
            'ddl_type': ddl_type,
            'issues': [],
            'warnings': [],
            'validated_at': datetime.utcnow().isoformat()
        }

        if ddl_type == 'CREATE_TABLE':
            validate_create_table(cursor, ddl_content, result)
        elif ddl_type == 'ALTER_TABLE':
            validate_alter_table(cursor, ddl_content, result)
        elif ddl_type == 'DROP_TABLE':
            validate_drop_table(cursor, ddl_content, result)
        elif ddl_type == 'CREATE_INDEX':
            validate_create_index(cursor, ddl_content, result)
        else:
            result['warnings'].append(f"ê²€ì¦ ë¯¸ì§€ì› DDL íƒ€ì…: {ddl_type}")

        cursor.close()
        connection.close()

        logger.info(f"ê²€ì¦ ì™„ë£Œ: valid={result['valid']}, issues={len(result['issues'])}")

        # S3ì— ê²°ê³¼ ì €ì¥
        try:
            timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
            s3_key = f"schema-validation/{database_secret}/{database}/{timestamp}.json"

            s3_client = boto3.client('s3', region_name=region)
            s3_client.put_object(
                Bucket=S3_BUCKET,
                Key=s3_key,
                Body=json.dumps(result, indent=2, ensure_ascii=False),
                ContentType='application/json'
            )

            logger.info(f"S3 ì €ì¥ ì™„ë£Œ: s3://{S3_BUCKET}/{s3_key}")
            result['s3_location'] = f"s3://{S3_BUCKET}/{s3_key}"

        except Exception as e:
            logger.error(f"S3 ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            result['s3_error'] = str(e)

        return {
            'statusCode': 200,
            'body': result
        }

    except Exception as e:
        logger.error(f"DDL ê²€ì¦ ì‹¤íŒ¨: {str(e)}", exc_info=True)

        if connection:
            try:
                connection.close()
            except:
                pass

        return {
            'statusCode': 500,
            'body': {
                'success': False,
                'error': str(e)
            }
        }
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- Lambda ë‚´ë¶€ì—ì„œ DB ì—°ê²° ê´€ë¦¬
- DDL íƒ€ì… ìë™ ê°ì§€
- í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€, ì™¸ë˜ í‚¤ ê²€ì¦
- S3 ìë™ ì €ì¥
- ì—ëŸ¬ ì²˜ë¦¬ ì™„ì „ì„±

---

### 5. Lambda explain_query í•¸ë“¤ëŸ¬

**ìœ„ì¹˜**: `lambda-functions/explain_query/handler.py:20-224`

```python
def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„ (EXPLAIN)

    ì…ë ¥:
    {
        "database_secret": "gamedb1-cluster",
        "database": "gamedb",
        "query": "SELECT * FROM users WHERE email = 'john@example.com'",
        "region": "ap-northeast-2"
    }

    ì¶œë ¥:
    {
        "success": True,
        "query": "SELECT * FROM users WHERE email = 'john@example.com'",
        "explain_data": [...],
        "performance_issues": [...],
        "performance_issue_count": 1,
        "recommendations": [...],
        "s3_location": "s3://..."
    }
    """

    connection = None

    try:
        database_secret = event.get('database_secret') or event.get('secret_name')
        database = event.get('database')
        query = event.get('query')

        if not all([database_secret, database, query]):
            return {
                'statusCode': 400,
                'body': {
                    'success': False,
                    'error': 'database_secret, database, query í•„ìˆ˜'
                }
            }

        region = event.get('region', 'ap-northeast-2')

        # Secrets Managerì—ì„œ ìê²©ì¦ëª… ê°€ì ¸ì˜¤ê¸°
        secretsmanager = boto3.client('secretsmanager', region_name=region)
        secret_response = secretsmanager.get_secret_value(SecretId=database_secret)
        credentials = json.loads(secret_response['SecretString'])

        # DB ì—°ê²°
        connection = pymysql.connect(
            host=credentials['host'],
            port=int(credentials.get('port', 3306)),
            user=credentials['username'],
            password=credentials['password'],
            database=database,
            connect_timeout=10
        )

        cursor = connection.cursor(pymysql.cursors.DictCursor)

        # ì¿¼ë¦¬ ì •ë¦¬
        query_clean = query.strip().rstrip(';')
        if query_clean.upper().startswith('EXPLAIN'):
            query_clean = query_clean[7:].strip()

        # EXPLAIN ì‹¤í–‰
        explain_query = f"EXPLAIN {query_clean}"
        cursor.execute(explain_query)
        explain_data = cursor.fetchall()

        # ì„±ëŠ¥ ì´ìŠˆ ë¶„ì„
        performance_issues = []
        recommendations = []

        for row in explain_data:
            # Full Table Scan ì²´í¬
            if row.get('type') == 'ALL':
                performance_issues.append({
                    'severity': 'HIGH',
                    'issue': 'Full Table Scan',
                    'table': row.get('table'),
                    'rows': row.get('rows'),
                    'description': f"í…Œì´ë¸” '{row.get('table')}'ì—ì„œ ì „ì²´ í…Œì´ë¸” ìŠ¤ìº” ë°œìƒ"
                })
                recommendations.append(f"í…Œì´ë¸” '{row.get('table')}'ì— ì¸ë±ìŠ¤ ì¶”ê°€ ê¶Œì¥")

            # Using filesort ì²´í¬
            if row.get('Extra') and 'Using filesort' in row.get('Extra'):
                performance_issues.append({
                    'severity': 'MEDIUM',
                    'issue': 'Using filesort',
                    'table': row.get('table'),
                    'description': 'ì •ë ¬ì„ ìœ„í•´ ì¶”ê°€ íŒŒì¼ ì •ë ¬ í•„ìš”'
                })
                recommendations.append('ORDER BY ì ˆì— ì‚¬ìš©ëœ ì»¬ëŸ¼ì— ì¸ë±ìŠ¤ ì¶”ê°€ ê¶Œì¥')

            # Using temporary ì²´í¬
            if row.get('Extra') and 'Using temporary' in row.get('Extra'):
                performance_issues.append({
                    'severity': 'MEDIUM',
                    'issue': 'Using temporary',
                    'table': row.get('table'),
                    'description': 'ì„ì‹œ í…Œì´ë¸” ì‚¬ìš©'
                })
                recommendations.append('GROUP BYë‚˜ DISTINCT ì‚¬ìš© ìµœì í™” ê¶Œì¥')

            # ë§ì€ í–‰ ìŠ¤ìº” ì²´í¬
            rows = row.get('rows', 0)
            if rows and rows > 100000:
                performance_issues.append({
                    'severity': 'HIGH',
                    'issue': 'Large Row Scan',
                    'table': row.get('table'),
                    'rows': rows,
                    'description': f"{rows:,}ê°œ í–‰ ìŠ¤ìº” ì˜ˆìƒ"
                })
                recommendations.append('WHERE ì¡°ê±´ ì¶”ê°€ ë˜ëŠ” ì¸ë±ìŠ¤ ìµœì í™” ê¶Œì¥')

        result = {
            'success': True,
            'query': query_clean,
            'explain_data': explain_data,
            'performance_issues': performance_issues,
            'performance_issue_count': len(performance_issues),
            'recommendations': recommendations,
            'analyzed_at': datetime.utcnow().isoformat()
        }

        cursor.close()
        connection.close()

        # S3ì— ê²°ê³¼ ì €ì¥
        timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
        query_hash = abs(hash(query_clean)) % 10000
        s3_key = f"explain-results/{database_secret}/{database}/{timestamp}_{query_hash}.json"

        s3_client = boto3.client('s3', region_name=region)
        s3_client.put_object(
            Bucket=S3_BUCKET,
            Key=s3_key,
            Body=json.dumps(result, indent=2, ensure_ascii=False, default=str),
            ContentType='application/json'
        )

        result['s3_location'] = f"s3://{S3_BUCKET}/{s3_key}"

        return {
            'statusCode': 200,
            'body': result
        }

    except Exception as e:
        logger.error(f"EXPLAIN ì‹¤íŒ¨: {str(e)}", exc_info=True)

        if connection:
            try:
                connection.close()
            except:
                pass

        return {
            'statusCode': 500,
            'body': {
                'success': False,
                'error': str(e)
            }
        }
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- EXPLAIN ìë™ ì‹¤í–‰
- Full Table Scan, filesort, temporary ìë™ ê°ì§€
- 100,000ê°œ ì´ìƒ í–‰ ìŠ¤ìº” ê²½ê³ 
- ê¶Œì¥ì‚¬í•­ ìë™ ìƒì„±
- S3 ì €ì¥

---

## Lambda í•¨ìˆ˜ ëª©ë¡ (ì‹¤ì œ ì‚¬ìš©)

> **ì´ 12ê°œ** Lambda í•¨ìˆ˜ê°€ ì‹¤ì œë¡œ `db_assistant_mcp_server.py`ì—ì„œ í˜¸ì¶œë©ë‹ˆë‹¤.

### í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ í•µì‹¬ í•¨ìˆ˜ (4ê°œ) â­

1. **validate_schema**
   - í•¨ìˆ˜ëª…: `db-assistant-validate-schema-dev`
   - ì—­í• : DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦ (CREATE TABLE, ALTER TABLE, DROP TABLE, CREATE INDEX ë“±)
   - í˜¸ì¶œ ìœ„ì¹˜: `db_assistant_mcp_server.py:9083`
   - ì‚¬ìš©: MCP ì„œë²„ â†’ Lambda (DB ì—°ê²°)

2. **explain_query**
   - í•¨ìˆ˜ëª…: `db-assistant-explain-query-dev`
   - ì—­í• : ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„ (EXPLAIN)
   - í˜¸ì¶œ ìœ„ì¹˜: `db_assistant_mcp_server.py:9145`
   - ì‚¬ìš©: MCP ì„œë²„ â†’ Lambda (DB ì—°ê²°)

3. **get_rds_cluster_info**
   - í•¨ìˆ˜ëª…: `db-assistant-get-rds-cluster-info-dev`
   - ì—­í• : RDS í´ëŸ¬ìŠ¤í„°/ì¸ìŠ¤í„´ìŠ¤ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
   - í˜¸ì¶œ ìœ„ì¹˜: `db_assistant_mcp_server.py:7369`
   - ì‚¬ìš©: MCP ì„œë²„ â†’ Lambda (RDS API)

4. **get_cloudwatch_metrics_raw**
   - í•¨ìˆ˜ëª…: `db-assistant-get-cloudwatch-metrics-raw-dev`
   - ì—­í• : CloudWatch ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (936ê°œ ë°ì´í„° í¬ì¸íŠ¸)
   - í˜¸ì¶œ ìœ„ì¹˜: `db_assistant_mcp_server.py:7400`
   - ì‚¬ìš©: MCP ì„œë²„ â†’ Lambda (CloudWatch API)

### ì„±ëŠ¥ ë¶„ì„ í•¨ìˆ˜ (6ê°œ)

5. **collect_cpu_intensive_queries**
   - í•¨ìˆ˜ëª…: `db-assistant-collect-cpu-intensive-queries-dev`
   - ì—­í• : CPU ì§‘ì•½ ì¿¼ë¦¬ ìˆ˜ì§‘ (CloudWatch Logs Insights)
   - í˜¸ì¶œ ìœ„ì¹˜: `db_assistant_mcp_server.py:8904`

6. **collect_temp_space_intensive_queries**
   - í•¨ìˆ˜ëª…: `db-assistant-collect-temp-space-intensive-queries-dev`
   - ì—­í• : ì„ì‹œ ê³µê°„ ì§‘ì•½ ì¿¼ë¦¬ ìˆ˜ì§‘ (tmp_table_size, sort_buffer_size)
   - í˜¸ì¶œ ìœ„ì¹˜: `db_assistant_mcp_server.py:8982`

7. **collect_memory_intensive_queries**
   - í•¨ìˆ˜ëª…: `db-assistant-collect-memory-intensive-queries-dev`
   - ì—­í• : ë©”ëª¨ë¦¬ ì§‘ì•½ ì¿¼ë¦¬ ìˆ˜ì§‘ (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ì¤€)
   - í˜¸ì¶œ ìœ„ì¹˜: `db_assistant_mcp_server.py:8825`

8. **collect_slow_queries_cloudwatch**
   - í•¨ìˆ˜ëª…: `db-assistant-collect-slow-queries-cloudwatch-dev`
   - ì—­í• : CloudWatch Logsì—ì„œ Slow Query ìˆ˜ì§‘
   - í˜¸ì¶œ ìœ„ì¹˜: `db_assistant_mcp_server.py:8544`

9. **collect_cluster_metrics**
   - í•¨ìˆ˜ëª…: `db-assistant-collect-cluster-metrics-dev`
   - ì—­í• : í´ëŸ¬ìŠ¤í„° ì „ì²´ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (ëª¨ë“  ë©¤ë²„ ì¸ìŠ¤í„´ìŠ¤)
   - í˜¸ì¶œ ìœ„ì¹˜: `db_assistant_mcp_server.py:6592`

10. **collect_cluster_events**
    - í•¨ìˆ˜ëª…: `db-assistant-collect-cluster-events-dev`
    - ì—­í• : í´ëŸ¬ìŠ¤í„° ì´ë²¤íŠ¸ ìˆ˜ì§‘ (ì¥ì• , ìœ ì§€ë³´ìˆ˜ ë“±)
    - í˜¸ì¶œ ìœ„ì¹˜: `db_assistant_mcp_server.py:6626`

### ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ í•¨ìˆ˜ (2ê°œ)

11. **get_secret**
    - í•¨ìˆ˜ëª…: `db-assistant-get-secret-dev`
    - ì—­í• : Secrets Managerì—ì„œ Secret ì¡°íšŒ
    - í˜¸ì¶œ ìœ„ì¹˜: `db_assistant_mcp_server.py:324` (ë™ê¸° í˜¸ì¶œ: `asyncio.run`)

12. **list_secrets**
    - í•¨ìˆ˜ëª…: `db-assistant-list-secrets-dev`
    - ì—­í• : Secrets Manager ëª©ë¡ ì¡°íšŒ (í‚¤ì›Œë“œ ê²€ìƒ‰)
    - í˜¸ì¶œ ìœ„ì¹˜: `db_assistant_mcp_server.py:345` (ë™ê¸° í˜¸ì¶œ: `asyncio.run`)

---

## ìµœì¢… ìš”ì•½

### í”„ë¡œì íŠ¸ í•µì‹¬

- **ë©”ì¸ íŒŒì¼**: `db_assistant_mcp_server.py` (500KB, 10000+ lines)
- **Lambda í•¨ìˆ˜**: ì‹¤ì œ ì‚¬ìš© 12ê°œ / ì „ì²´ 36ê°œ
  - í•µì‹¬ 4ê°œ: validate_schema, explain_query, get_rds_cluster_info, get_cloudwatch_metrics_raw
  - ì„±ëŠ¥ ë¶„ì„ 6ê°œ: CPU/ë©”ëª¨ë¦¬/ì„ì‹œê³µê°„ ì§‘ì•½ ì¿¼ë¦¬ ìˆ˜ì§‘, Slow Query, í´ëŸ¬ìŠ¤í„° ë©”íŠ¸ë¦­/ì´ë²¤íŠ¸
  - ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ 2ê°œ: get_secret, list_secrets
- **ì•„í‚¤í…ì²˜**: í•˜ì´ë¸Œë¦¬ë“œ (Lambda ë°ì´í„° ìˆ˜ì§‘ + EC2 ë³µì¡í•œ ë¶„ì„)
- **AI í†µí•©**: Bedrock Knowledge Base RAG + Claude Sonnet 4

### ì£¼ìš” ê¸°ëŠ¥

1. **SQL ê²€ì¦**: DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦, DML EXPLAIN ë¶„ì„
2. **ì„±ëŠ¥ ë¶„ì„**: 936ê°œ CloudWatch ë©”íŠ¸ë¦­, Pandas ë°ì´í„° ë¶„ì„
3. **AI ê¶Œì¥ì‚¬í•­**: RAG ê²€ìƒ‰ + Claude AI ë¶„ì„
4. **ë¦¬í¬íŠ¸**: HTML + CSV + SQL íŒŒì¼ ìë™ ìƒì„±

### ë°°í¬ ìƒíƒœ

- **Lambda**: 12ê°œ í•¨ìˆ˜ ì‹¤ì œ ì‚¬ìš© ì¤‘ / 36ê°œ ë°°í¬ (ap-northeast-2)
  - â­ í•µì‹¬ 4ê°œ: validate_schema, explain_query, get_rds_cluster_info, get_cloudwatch_metrics_raw
  - ğŸ“Š ì„±ëŠ¥ ë¶„ì„ 6ê°œ: collect_cpu/memory/temp_space/slow_queries, collect_cluster_metrics/events
  - ğŸ”‘ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ 2ê°œ: get_secret, list_secrets
- **EC2**: MCP ì„œë²„ ì‹¤í–‰ ì¤‘ (db_assistant_mcp_server.py)
- **S3**: ë¦¬í¬íŠ¸ ì €ì¥ (`db-assistant-reports`, `db-assistant-query-results-dev`)
- **Amazon Q CLI**: MCP í”„ë¡œí† ì½œ ì—°ë™ ì™„ë£Œ

---

## Lambda ì†ŒìŠ¤ì½”ë“œ ì „ì²´

### 1. validate_schema Lambda í•¨ìˆ˜ (ì™„ì „í•œ ì½”ë“œ)

**íŒŒì¼**: `lambda-functions/validate_schema/handler.py`

```python
"""
Lambda Function: validate-schema
DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë° S3 ì €ì¥
"""

import json
import logging
import re
from typing import Dict, Any, List
from datetime import datetime
import boto3
import pymysql

logger = logging.getLogger()
logger.setLevel(logging.INFO)

S3_BUCKET = 'db-assistant-query-results-dev'


def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    DDL ìŠ¤í‚¤ë§ˆ ê²€ì¦

    Parameters:
    - event: {
        "database_secret": "gamedb1-cluster",
        "database": "gamedb",
        "ddl_content": "CREATE TABLE users (...)",
        "region": "ap-northeast-2"
      }

    Returns:
    - statusCode: 200 (ì„±ê³µ) / 400 (ì…ë ¥ ì˜¤ë¥˜) / 500 (ì‹¤íŒ¨)
    - body: {
        "success": true/false,
        "valid": true/false,
        "ddl_type": "CREATE_TABLE",
        "issues": [...],
        "warnings": [...],
        "s3_location": "s3://..."
      }
    """
    connection = None

    try:
        database_secret = event.get('database_secret')
        database = event.get('database')
        ddl_content = event.get('ddl_content')
        region = event.get('region', 'ap-northeast-2')

        if not all([database_secret, database, ddl_content]):
            return {
                'statusCode': 400,
                'body': {
                    'success': False,
                    'error': 'database_secret, database, ddl_content í•„ìˆ˜'
                }
            }

        logger.info(f"DDL ê²€ì¦ ì‹œì‘: {database_secret}/{database}")

        # DDL íƒ€ì… ë¶„ì„
        ddl_type = detect_ddl_type(ddl_content)
        logger.info(f"DDL íƒ€ì…: {ddl_type}")

        # Secrets Managerì—ì„œ DB ì ‘ì† ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        secrets_client = boto3.client('secretsmanager', region_name=region)
        secret_response = secrets_client.get_secret_value(SecretId=database_secret)
        secret = json.loads(secret_response['SecretString'])

        # DB ì—°ê²°
        connection = pymysql.connect(
            host=secret.get('host'),
            port=int(secret.get('port', 3306)),
            user=secret.get('username'),
            password=secret.get('password'),
            database=database,
            connect_timeout=10
        )

        cursor = connection.cursor()
        logger.info("DB ì—°ê²° ì„±ê³µ")

        # ê²€ì¦ ìˆ˜í–‰
        result = {
            'success': True,
            'valid': True,
            'ddl_type': ddl_type,
            'issues': [],
            'warnings': [],
            'validated_at': datetime.utcnow().isoformat()
        }

        if ddl_type == 'CREATE_TABLE':
            validate_create_table(cursor, ddl_content, result)
        elif ddl_type == 'ALTER_TABLE':
            validate_alter_table(cursor, ddl_content, result)
        elif ddl_type == 'DROP_TABLE':
            validate_drop_table(cursor, ddl_content, result)
        elif ddl_type == 'CREATE_INDEX':
            validate_create_index(cursor, ddl_content, result)
        else:
            result['warnings'].append(f"ê²€ì¦ ë¯¸ì§€ì› DDL íƒ€ì…: {ddl_type}")

        cursor.close()
        connection.close()

        logger.info(f"ê²€ì¦ ì™„ë£Œ: valid={result['valid']}, issues={len(result['issues'])}")

        # S3ì— ê²°ê³¼ ì €ì¥
        try:
            timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
            s3_key = f"schema-validation/{database_secret}/{database}/{timestamp}.json"

            s3_client = boto3.client('s3', region_name=region)
            s3_client.put_object(
                Bucket=S3_BUCKET,
                Key=s3_key,
                Body=json.dumps(result, indent=2, ensure_ascii=False),
                ContentType='application/json'
            )

            logger.info(f"S3 ì €ì¥ ì™„ë£Œ: s3://{S3_BUCKET}/{s3_key}")
            result['s3_location'] = f"s3://{S3_BUCKET}/{s3_key}"

        except Exception as e:
            logger.error(f"S3 ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            result['s3_error'] = str(e)

        return {
            'statusCode': 200,
            'body': result
        }

    except Exception as e:
        logger.error(f"DDL ê²€ì¦ ì‹¤íŒ¨: {str(e)}", exc_info=True)

        if connection:
            try:
                connection.close()
            except:
                pass

        return {
            'statusCode': 500,
            'body': {
                'success': False,
                'error': str(e)
            }
        }


def detect_ddl_type(ddl_content: str) -> str:
    """DDL íƒ€ì… ê°ì§€"""
    ddl_upper = ddl_content.strip().upper()

    if ddl_upper.startswith('CREATE TABLE'):
        return 'CREATE_TABLE'
    elif ddl_upper.startswith('ALTER TABLE'):
        return 'ALTER_TABLE'
    elif ddl_upper.startswith('DROP TABLE'):
        return 'DROP_TABLE'
    elif ddl_upper.startswith('CREATE INDEX') or ddl_upper.startswith('CREATE UNIQUE INDEX'):
        return 'CREATE_INDEX'
    elif ddl_upper.startswith('DROP INDEX'):
        return 'DROP_INDEX'
    else:
        return 'UNKNOWN'


def validate_create_table(cursor, ddl_content: str, result: Dict):
    """CREATE TABLE ê²€ì¦"""
    # í…Œì´ë¸” ì´ë¦„ ì¶”ì¶œ
    match = re.search(r'CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?`?(\w+)`?', ddl_content, re.IGNORECASE)
    if not match:
        result['valid'] = False
        result['issues'].append("í…Œì´ë¸” ì´ë¦„ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŒ")
        return

    table_name = match.group(1)
    result['table_name'] = table_name

    # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    cursor.execute("SHOW TABLES LIKE %s", (table_name,))
    if cursor.fetchone():
        result['warnings'].append(f"í…Œì´ë¸” '{table_name}'ì´ ì´ë¯¸ ì¡´ì¬í•¨ (IF NOT EXISTS ì‚¬ìš© ê¶Œì¥)")

    # ì™¸ë˜ í‚¤ ê²€ì¦
    fk_pattern = r'FOREIGN\s+KEY\s+\([^)]+\)\s+REFERENCES\s+`?(\w+)`?'
    foreign_keys = re.findall(fk_pattern, ddl_content, re.IGNORECASE)

    for ref_table in foreign_keys:
        cursor.execute("SHOW TABLES LIKE %s", (ref_table,))
        if not cursor.fetchone():
            result['valid'] = False
            result['issues'].append(f"ì™¸ë˜ í‚¤ ì°¸ì¡° í…Œì´ë¸” '{ref_table}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")


def validate_alter_table(cursor, ddl_content: str, result: Dict):
    """ALTER TABLE ê²€ì¦"""
    # í…Œì´ë¸” ì´ë¦„ ì¶”ì¶œ
    match = re.search(r'ALTER\s+TABLE\s+`?(\w+)`?', ddl_content, re.IGNORECASE)
    if not match:
        result['valid'] = False
        result['issues'].append("í…Œì´ë¸” ì´ë¦„ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŒ")
        return

    table_name = match.group(1)
    result['table_name'] = table_name

    # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    cursor.execute("SHOW TABLES LIKE %s", (table_name,))
    if not cursor.fetchone():
        result['valid'] = False
        result['issues'].append(f"í…Œì´ë¸” '{table_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")


def validate_drop_table(cursor, ddl_content: str, result: Dict):
    """DROP TABLE ê²€ì¦"""
    # í…Œì´ë¸” ì´ë¦„ ì¶”ì¶œ
    match = re.search(r'DROP\s+TABLE\s+(?:IF\s+EXISTS\s+)?`?(\w+)`?', ddl_content, re.IGNORECASE)
    if not match:
        result['valid'] = False
        result['issues'].append("í…Œì´ë¸” ì´ë¦„ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŒ")
        return

    table_name = match.group(1)
    result['table_name'] = table_name

    # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    cursor.execute("SHOW TABLES LIKE %s", (table_name,))
    if not cursor.fetchone():
        result['warnings'].append(f"í…Œì´ë¸” '{table_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ (IF EXISTS ì‚¬ìš© ê¶Œì¥)")


def validate_create_index(cursor, ddl_content: str, result: Dict):
    """CREATE INDEX ê²€ì¦"""
    # í…Œì´ë¸” ì´ë¦„ ì¶”ì¶œ
    match = re.search(r'ON\s+`?(\w+)`?', ddl_content, re.IGNORECASE)
    if not match:
        result['valid'] = False
        result['issues'].append("í…Œì´ë¸” ì´ë¦„ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŒ")
        return

    table_name = match.group(1)
    result['table_name'] = table_name

    # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    cursor.execute("SHOW TABLES LIKE %s", (table_name,))
    if not cursor.fetchone():
        result['valid'] = False
        result['issues'].append(f"í…Œì´ë¸” '{table_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
```

---

### 2. explain_query Lambda í•¨ìˆ˜ (ì™„ì „í•œ ì½”ë“œ)

**íŒŒì¼**: `lambda-functions/explain_query/handler.py`

```python
"""
Lambda Function: explain_query
ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„ (EXPLAIN) ë° S3 ì €ì¥
"""

import json
import logging
from typing import Dict, Any
from datetime import datetime

import boto3
import pymysql

logger = logging.getLogger()
logger.setLevel(logging.INFO)

S3_BUCKET = 'db-assistant-query-results-dev'


def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„ (EXPLAIN)

    ì…ë ¥:
    {
        "secret_name": "rds/gamedb1/admin",
        "database": "gamedb",
        "query": "SELECT * FROM users WHERE email = 'john@example.com'",
        "format": "json",  # "traditional", "json", "tree"
        "region": "ap-northeast-2"
    }

    ì¶œë ¥:
    {
        "status": "success",
        "query": "SELECT * FROM users WHERE email = 'john@example.com'",
        "explain_result": [
            {
                "id": 1,
                "select_type": "SIMPLE",
                "table": "users",
                "type": "ALL",
                "possible_keys": null,
                "key": null,
                "rows": 10000,
                "Extra": "Using where"
            }
        ],
        "analysis": {
            "table_scan": true,
            "index_used": false,
            "rows_examined": 10000,
            "recommendations": ["email ì»¬ëŸ¼ì— ì¸ë±ìŠ¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”"]
        }
    }
    """

    logger.info("=== EXPLAIN ë¶„ì„ ì‹œì‘ ===")
    logger.info(f"Event: {json.dumps(event, default=str)}")

    connection = None

    try:
        database_secret = event.get('database_secret') or event.get('secret_name')
        database = event.get('database')
        query = event.get('query')

        if not all([database_secret, database, query]):
            return {
                'statusCode': 400,
                'body': {
                    'success': False,
                    'error': 'database_secret, database, query í•„ìˆ˜'
                }
            }

        region = event.get('region', 'ap-northeast-2')

        logger.info(f"EXPLAIN ì‹¤í–‰ ì‹œì‘: {database_secret}/{database}")
        logger.info(f"Query: {query[:100]}...")

        # Secrets Managerì—ì„œ ìê²©ì¦ëª… ê°€ì ¸ì˜¤ê¸°
        secretsmanager = boto3.client('secretsmanager', region_name=region)
        secret_response = secretsmanager.get_secret_value(SecretId=database_secret)
        credentials = json.loads(secret_response['SecretString'])

        # DB ì—°ê²°
        connection = pymysql.connect(
            host=credentials['host'],
            port=int(credentials.get('port', 3306)),
            user=credentials['username'],
            password=credentials['password'],
            database=database,
            connect_timeout=10
        )

        cursor = connection.cursor(pymysql.cursors.DictCursor)
        logger.info("DB ì—°ê²° ì„±ê³µ")

        # ì¿¼ë¦¬ ì •ë¦¬
        query_clean = query.strip().rstrip(';')
        if query_clean.upper().startswith('EXPLAIN'):
            query_clean = query_clean[7:].strip()

        # EXPLAIN ì‹¤í–‰
        explain_query = f"EXPLAIN {query_clean}"
        cursor.execute(explain_query)
        explain_data = cursor.fetchall()

        logger.info(f"EXPLAIN ê²°ê³¼: {len(explain_data)}ê°œ í–‰")

        # ì„±ëŠ¥ ì´ìŠˆ ë¶„ì„
        performance_issues = []
        recommendations = []

        for row in explain_data:
            # bytes -> str ë³€í™˜
            row_clean = {}
            for k, v in row.items():
                if isinstance(v, bytes):
                    row_clean[k] = v.decode('utf-8')
                else:
                    row_clean[k] = v

            # Full Table Scan ì²´í¬
            if row_clean.get('type') == 'ALL':
                performance_issues.append({
                    'severity': 'HIGH',
                    'issue': 'Full Table Scan',
                    'table': row_clean.get('table'),
                    'rows': row_clean.get('rows'),
                    'description': f"í…Œì´ë¸” '{row_clean.get('table')}'ì—ì„œ ì „ì²´ í…Œì´ë¸” ìŠ¤ìº” ë°œìƒ"
                })
                recommendations.append(f"í…Œì´ë¸” '{row_clean.get('table')}'ì— ì¸ë±ìŠ¤ ì¶”ê°€ ê¶Œì¥")

            # Using filesort ì²´í¬
            if row_clean.get('Extra') and 'Using filesort' in row_clean.get('Extra'):
                performance_issues.append({
                    'severity': 'MEDIUM',
                    'issue': 'Using filesort',
                    'table': row_clean.get('table'),
                    'description': 'ì •ë ¬ì„ ìœ„í•´ ì¶”ê°€ íŒŒì¼ ì •ë ¬ í•„ìš”'
                })
                recommendations.append('ORDER BY ì ˆì— ì‚¬ìš©ëœ ì»¬ëŸ¼ì— ì¸ë±ìŠ¤ ì¶”ê°€ ê¶Œì¥')

            # Using temporary ì²´í¬
            if row_clean.get('Extra') and 'Using temporary' in row_clean.get('Extra'):
                performance_issues.append({
                    'severity': 'MEDIUM',
                    'issue': 'Using temporary',
                    'table': row_clean.get('table'),
                    'description': 'ì„ì‹œ í…Œì´ë¸” ì‚¬ìš©'
                })
                recommendations.append('GROUP BYë‚˜ DISTINCT ì‚¬ìš© ìµœì í™” ê¶Œì¥')

            # ë§ì€ í–‰ ìŠ¤ìº” ì²´í¬
            rows = row_clean.get('rows', 0)
            if rows and rows > 100000:
                performance_issues.append({
                    'severity': 'HIGH',
                    'issue': 'Large Row Scan',
                    'table': row_clean.get('table'),
                    'rows': rows,
                    'description': f"{rows:,}ê°œ í–‰ ìŠ¤ìº” ì˜ˆìƒ"
                })
                recommendations.append('WHERE ì¡°ê±´ ì¶”ê°€ ë˜ëŠ” ì¸ë±ìŠ¤ ìµœì í™” ê¶Œì¥')

        result = {
            'success': True,
            'query': query_clean,
            'explain_data': explain_data,
            'performance_issues': performance_issues,
            'performance_issue_count': len(performance_issues),
            'recommendations': recommendations,
            'analyzed_at': datetime.utcnow().isoformat()
        }

        cursor.close()
        connection.close()

        logger.info(f"ë¶„ì„ ì™„ë£Œ: {len(performance_issues)}ê°œ ì´ìŠˆ ë°œê²¬")

        # S3ì— ê²°ê³¼ ì €ì¥
        try:
            timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
            query_hash = abs(hash(query_clean)) % 10000
            s3_key = f"explain-results/{database_secret}/{database}/{timestamp}_{query_hash}.json"

            s3_client = boto3.client('s3', region_name=region)
            s3_client.put_object(
                Bucket=S3_BUCKET,
                Key=s3_key,
                Body=json.dumps(result, indent=2, ensure_ascii=False, default=str),
                ContentType='application/json'
            )

            logger.info(f"S3 ì €ì¥ ì™„ë£Œ: s3://{S3_BUCKET}/{s3_key}")
            result['s3_location'] = f"s3://{S3_BUCKET}/{s3_key}"

        except Exception as e:
            logger.error(f"S3 ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            result['s3_error'] = str(e)

        return {
            'statusCode': 200,
            'body': result
        }

    except Exception as e:
        logger.error(f"EXPLAIN ì‹¤íŒ¨: {str(e)}", exc_info=True)

        if connection:
            try:
                connection.close()
            except:
                pass

        return {
            'statusCode': 500,
            'body': {
                'success': False,
                'error': str(e)
            }
        }
```

---

### 3. get_rds_cluster_info Lambda í•¨ìˆ˜ (ì™„ì „í•œ ì½”ë“œ)

**íŒŒì¼**: `lambda-functions/get_rds_cluster_info/handler.py`

```python
"""
RDS í´ëŸ¬ìŠ¤í„°/ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ ì¡°íšŒ Lambda í•¨ìˆ˜
ì›ë³¸ ì„œë²„ì—ì„œ í˜¸ì¶œí•˜ì—¬ RDS API ë¶€ë¶„ë§Œ ì²˜ë¦¬
"""
import json
import logging
import boto3
from typing import Dict, Any, Optional

logger = logging.getLogger()
logger.setLevel(logging.INFO)


def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    RDS í´ëŸ¬ìŠ¤í„° ë˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ ì¡°íšŒ

    ì…ë ¥:
        - identifier: í´ëŸ¬ìŠ¤í„° ID ë˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ ID
        - region: AWS ë¦¬ì „ (ê¸°ë³¸ê°’: ap-northeast-2)

    ì¶œë ¥:
        - type: "cluster" | "instance"
        - info: í´ëŸ¬ìŠ¤í„° ë˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ ì •ë³´
        - members: í´ëŸ¬ìŠ¤í„°ì¸ ê²½ìš° ë©¤ë²„ ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡
    """
    logger.info(f"=== RDS ì •ë³´ ì¡°íšŒ ì‹œì‘ ===")
    logger.info(f"Event: {json.dumps(event)}")

    try:
        identifier = event.get('identifier')
        region = event.get('region', 'ap-northeast-2')

        if not identifier:
            return {
                'statusCode': 400,
                'body': json.dumps({'error': 'identifierê°€ í•„ìš”í•©ë‹ˆë‹¤'})
            }

        rds_client = boto3.client('rds', region_name=region)

        # ë¨¼ì € í´ëŸ¬ìŠ¤í„°ë¡œ ì¡°íšŒ ì‹œë„
        try:
            logger.info(f"í´ëŸ¬ìŠ¤í„° ì¡°íšŒ ì‹œë„: {identifier}")
            cluster_response = rds_client.describe_db_clusters(
                DBClusterIdentifier=identifier
            )

            if cluster_response['DBClusters']:
                cluster = cluster_response['DBClusters'][0]

                # ë©¤ë²„ ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ ìˆ˜ì§‘
                members = []
                for member in cluster.get('DBClusterMembers', []):
                    member_id = member['DBInstanceIdentifier']
                    is_writer = member.get('IsClusterWriter', False)

                    # ê° ë©¤ë²„ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ
                    try:
                        instance_response = rds_client.describe_db_instances(
                            DBInstanceIdentifier=member_id
                        )
                        if instance_response['DBInstances']:
                            instance = instance_response['DBInstances'][0]
                            members.append({
                                'identifier': member_id,
                                'is_writer': is_writer,
                                'instance_class': instance.get('DBInstanceClass'),
                                'status': instance.get('DBInstanceStatus'),
                                'availability_zone': instance.get('AvailabilityZone'),
                                'endpoint': instance.get('Endpoint', {}).get('Address')
                            })
                    except Exception as e:
                        logger.warning(f"ë©¤ë²„ {member_id} ì¡°íšŒ ì‹¤íŒ¨: {e}")

                result = {
                    'type': 'cluster',
                    'identifier': cluster['DBClusterIdentifier'],
                    'status': cluster.get('Status'),
                    'engine': cluster.get('Engine'),
                    'engine_version': cluster.get('EngineVersion'),
                    'endpoint': cluster.get('Endpoint'),
                    'reader_endpoint': cluster.get('ReaderEndpoint'),
                    'port': cluster.get('Port'),
                    'master_username': cluster.get('MasterUsername'),
                    'multi_az': cluster.get('MultiAZ', False),
                    'members': members,
                    'member_count': len(members)
                }

                logger.info(f"í´ëŸ¬ìŠ¤í„° ì¡°íšŒ ì„±ê³µ: {identifier}, ë©¤ë²„: {len(members)}ê°œ")

                return {
                    'statusCode': 200,
                    'body': json.dumps(result, default=str, ensure_ascii=False)
                }

        except rds_client.exceptions.DBClusterNotFoundFault:
            logger.info(f"{identifier}ëŠ” í´ëŸ¬ìŠ¤í„°ê°€ ì•„ë‹˜, ì¸ìŠ¤í„´ìŠ¤ë¡œ ì¡°íšŒ")

        # ì¸ìŠ¤í„´ìŠ¤ë¡œ ì¡°íšŒ
        try:
            logger.info(f"ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ì‹œë„: {identifier}")
            instance_response = rds_client.describe_db_instances(
                DBInstanceIdentifier=identifier
            )

            if instance_response['DBInstances']:
                instance = instance_response['DBInstances'][0]

                result = {
                    'type': 'instance',
                    'identifier': instance['DBInstanceIdentifier'],
                    'instance_class': instance.get('DBInstanceClass'),
                    'engine': instance.get('Engine'),
                    'engine_version': instance.get('EngineVersion'),
                    'status': instance.get('DBInstanceStatus'),
                    'availability_zone': instance.get('AvailabilityZone'),
                    'multi_az': instance.get('MultiAZ', False),
                    'endpoint': instance.get('Endpoint', {}).get('Address'),
                    'port': instance.get('Endpoint', {}).get('Port'),
                    'allocated_storage': instance.get('AllocatedStorage'),
                    'storage_type': instance.get('StorageType'),
                    'master_username': instance.get('MasterUsername'),
                    'db_cluster_identifier': instance.get('DBClusterIdentifier')
                }

                logger.info(f"ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ì„±ê³µ: {identifier}")

                return {
                    'statusCode': 200,
                    'body': json.dumps(result, default=str, ensure_ascii=False)
                }

        except rds_client.exceptions.DBInstanceNotFoundFault:
            logger.error(f"{identifier}ëŠ” í´ëŸ¬ìŠ¤í„°ë„ ì¸ìŠ¤í„´ìŠ¤ë„ ì•„ë‹˜")
            return {
                'statusCode': 404,
                'body': json.dumps({'error': f'{identifier}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'})
            }

        return {
            'statusCode': 404,
            'body': json.dumps({'error': f'{identifier}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'})
        }

    except Exception as e:
        logger.error(f"RDS ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)}, ensure_ascii=False)
        }
```

---

### 4. get_cloudwatch_metrics_raw Lambda í•¨ìˆ˜ (ì™„ì „í•œ ì½”ë“œ)

**íŒŒì¼**: `lambda-functions/get_cloudwatch_metrics_raw/handler.py`

```python
"""
CloudWatch ë©”íŠ¸ë¦­ Raw ë°ì´í„° ìˆ˜ì§‘ Lambda í•¨ìˆ˜
ì›ë³¸ ì„œë²„ì—ì„œ í˜¸ì¶œí•˜ì—¬ CloudWatch API ë¶€ë¶„ë§Œ ì²˜ë¦¬
"""
import json
import logging
import boto3
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional

logger = logging.getLogger()
logger.setLevel(logging.INFO)


def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    CloudWatchì—ì„œ RDS ë©”íŠ¸ë¦­ ìˆ˜ì§‘

    ì…ë ¥:
        - instance_identifier: ì¸ìŠ¤í„´ìŠ¤ ID
        - metrics: ìˆ˜ì§‘í•  ë©”íŠ¸ë¦­ ë¦¬ìŠ¤íŠ¸ (ì„ íƒ)
        - hours: ìˆ˜ì§‘ ê¸°ê°„ (ì‹œê°„, ê¸°ë³¸ê°’: 24)
        - region: AWS ë¦¬ì „ (ê¸°ë³¸ê°’: ap-northeast-2)
        - period: ë°ì´í„° í¬ì¸íŠ¸ ê°„ê²©(ì´ˆ, ê¸°ë³¸ê°’: 300)

    ì¶œë ¥:
        - metrics_data: [{timestamp, metric, value}, ...]
        - summary: {metric_count, datapoint_count}
    """
    logger.info(f"=== CloudWatch ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘ ===")
    logger.info(f"Event: {json.dumps(event, default=str)}")

    try:
        instance_id = event.get('instance_identifier')
        region = event.get('region', 'ap-northeast-2')
        hours = event.get('hours', 24)
        period = event.get('period', 300)  # 5ë¶„ ê°„ê²©

        # ê¸°ë³¸ ë©”íŠ¸ë¦­ ëª©ë¡
        default_metrics = [
            'CPUUtilization',
            'DatabaseConnections',
            'FreeableMemory',
            'ReadLatency',
            'WriteLatency',
            'ReadIOPS',
            'WriteIOPS',
            'ReadThroughput',
            'WriteThroughput',
            'NetworkReceiveThroughput',
            'NetworkTransmitThroughput',
            'FreeStorageSpace'
        ]

        metrics = event.get('metrics', default_metrics)

        if not instance_id:
            return {
                'statusCode': 400,
                'body': json.dumps({'error': 'instance_identifierê°€ í•„ìš”í•©ë‹ˆë‹¤'})
            }

        cloudwatch = boto3.client('cloudwatch', region_name=region)

        # ì‹œê°„ ë²”ìœ„ ì„¤ì •
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=hours)

        logger.info(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘: {instance_id}, ê¸°ê°„: {start_time} ~ {end_time}")

        # ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        all_data = []
        failed_metrics = []

        # ê° ë©”íŠ¸ë¦­ì— ëŒ€í•´ ë°ì´í„° ìˆ˜ì§‘
        for metric in metrics:
            try:
                response = cloudwatch.get_metric_statistics(
                    Namespace='AWS/RDS',
                    MetricName=metric,
                    Dimensions=[
                        {
                            'Name': 'DBInstanceIdentifier',
                            'Value': instance_id
                        }
                    ],
                    StartTime=start_time,
                    EndTime=end_time,
                    Period=period,
                    Statistics=['Average', 'Maximum', 'Minimum']
                )

                # ì‘ë‹µì—ì„œ ë°ì´í„° ì¶”ì¶œ
                for point in response['Datapoints']:
                    all_data.append({
                        'timestamp': point['Timestamp'].isoformat(),
                        'metric': metric,
                        'average': point.get('Average'),
                        'maximum': point.get('Maximum'),
                        'minimum': point.get('Minimum'),
                        'unit': point.get('Unit', '')
                    })

                logger.info(f"ë©”íŠ¸ë¦­ {metric}: {len(response['Datapoints'])}ê°œ ìˆ˜ì§‘")

            except Exception as e:
                logger.error(f"ë©”íŠ¸ë¦­ {metric} ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                failed_metrics.append(metric)

        result = {
            'instance_identifier': instance_id,
            'metrics_data': all_data,
            'summary': {
                'requested_metrics': len(metrics),
                'successful_metrics': len(metrics) - len(failed_metrics),
                'failed_metrics': failed_metrics,
                'total_datapoints': len(all_data),
                'period_hours': hours,
                'start_time': start_time.isoformat(),
                'end_time': end_time.isoformat()
            }
        }

        logger.info(f"ìˆ˜ì§‘ ì™„ë£Œ: {len(all_data)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")

        return {
            'statusCode': 200,
            'body': json.dumps(result, ensure_ascii=False)
        }

    except Exception as e:
        logger.error(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)}, ensure_ascii=False)
        }
```

---

**ì‘ì„±ì¼**: 2025-10-25
**ë²„ì „**: v5.2 (í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ + Lambda í†µí•© + ë¦¬ì „ ì •ë³´ ëª…ì‹œ)
**ìƒíƒœ**: ëª¨ë“  ê¸°ëŠ¥ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ, README ì—…ë°ì´íŠ¸ ì™„ë£Œ
